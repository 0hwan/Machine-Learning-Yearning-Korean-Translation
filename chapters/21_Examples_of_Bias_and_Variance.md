## 21 Examples of Bias and Variance

계속 언급되어온 고양이를 분류하는 알고리즘의 예를 다시 떠올려보자. 사람수준의 성능을 가진, ***`이상적인`*** 알고리즘은 이 작업에 대하여 거의 완벽에 근접한 성능을 보여줄 것이다.

알고리즘의 성능이 다음과 같다고 가정해 보자:
- 학습 데이터셋에 대한 에러율 = 1%
- 개발 데이터셋에 대한 에러율 = 11%

어떤 문제를 있을 수 있을까? 이전 챕터에서정의된 내용을 적용해 보면, 1%의 ***`편향`*** 과 10%의 ***`분산`*** (= 11%-1%) 을 생각해 볼 수 있겠다. 그렇다면 이 수치는 높은 ***`분산`*** 을 말하고 있다는걸 알 수 있다. 분류 알고리즘은 학습 데이터셋에 대하여 매우 낮은 에러율을 보여주고 있지만, 이 결과의 개발 데이터셋에 대한 일반화는 실패하고 있다. 이러한 상황을 흔히 ***`과적합(오버피팅)`*** 이라고도 부른다.

또 다른 경우를 생각해 보자:
- 학습 데이터셋에 대한 에러율 = 15%
- 개발 데이터셋에 대한 에러율 = 16%

이번에는 ***`편향`*** 이 15%, ***`분산`*** 이 1%라고 생각해 볼 수 있겠다. 이 분류 알고리즘은 개발 데이터셋에 대하여 15%라는 나쁜 에러율을 보여주긴 하지만, 개발 데이터셋에 대한 에러율이 학습 데이터셋에 대한 것에 비해 별로 크지 않다. 이 경우, 알고리즘은 높은 ***`편향`*** 을 가지고 있지만, 낮은 ***`분산`*** 을 보여준다고 할 수 있다. 이 결과는 흔히 ***`희소적합(언더피팅)`*** 이라고도 불린다.

다음의 경우도 한번 살펴보자:
- 학습 데이터셋에 대한 에러율 = 15%
- 개발 데이터셋에 대한 에러율 = 30%

위 결과로 15%의 ***`편향`*** , 15%의 ***`분산`*** 을 측정해 볼 수 있다. 이 분류 알고리즘은 높은 ***`편향`*** 과 높은 ***`분산`*** 모두를 가진다고 볼 수 있겠다. 개발 데이터셋에 대한 좋지 못한 성능이 높은 ***`편향`*** 으로 나타났으며, 개발 데이터셋에 대하여 그보다 더 좋지 못한 결과로 높은 ***`분산`*** 또한 나타났다. 분류 알고리즘에 대하여 동시에 ***`과적합`*** 과 ***`희소적합`*** 이 나타났으므로 ***`과적합`*** 또는 ***`희소적합`*** 이라는 용어가 적용되기 어렵운 상황이다.

마지막으로 다음 경우를 한번 살펴 보자:
- 학습 데이터셋에 대한 에러율 = 0.5%
- 개발 데이터셋에 대한 에러율 = 1%

마지막 경우의 분류 알고리즘은 매우 좋은 성능을 보여주고 있다고 할 수 있겠다. 낮은 ***`편향`*** 과 ***`분산`*** 이 이 설명을 뒷받침 한다. 이 경우에는 좋은 성능을 얻을 수 있음을 의미하고, 이를 축하해도 좋을 일이다!
