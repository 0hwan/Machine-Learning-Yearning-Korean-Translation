## 21 Examples of Bias and Variance

계속 언급되어온 고양이 분류기를 다시 떠올려 보자. 사람만큼의 성능을 보이는 "이상적인" 분류기는 이 작어베 대해서 거의 완벽에 가까운 성능을 보여줄 것이다.

알고리즘의 성능이 다음과 같다고 가정해 보자:

- 학습 (데이터셋에 대한) 에러율 = 1%
- 개발 (데이터셋에 대한) 에러율 = 11%

어떤 문제를 가지고 있는가? 앞 챕터에서의 정의를 적용해 보자면, "편향"이 1%, "분산"이 10% (=11%-1%) 라고 볼 수 있겠다. 그러면, 이는 높은 "분산"을 보여준다. 분류 알고리즘은 매우 낮은 학습 데이터셋에 대한 에러율을 보여주고 있지만, 이 결과를 개발 데이터셋에 대해서 일반화 하는데에는 실패하고 있다. 이 결과는 "과적합(오버피팅)" 이라고도 불린다.

다음의 경우는 어떤지 살펴보자:

- 학습 (데이터셋에 대한) 에러율 = 15%
- 개발 (데이터셋에 대한) 에러율 = 16%

"편향"이 15%로 측정되고, "분산"은 1%로 볼 수 있겠다. 이 분류 알고리즘은 개발 데이터셋에 대해서 15%라는 나쁜 성능을 보여주긴 하지만, 개발 데이터셋에 대한 에러가 학습 데이터셋에 대한 것보다 그렇게 크지 않다. 이 경우에 알고리즘이 높은 "편향"을 가지고 있지만, 낮은 "분산"을 보여준다고 할 수 있다. 이 결과는 "희소적합(언더피팅)" 이라고도 불린다.

다음의 경우도 한번 살펴보자:

- 학습 (데이터셋에 대한) 에러율 = 15%
- 개발 (데이터셋에 대한) 에러율 = 30%

"편향"이 15%, "분산"이 15%라고 측정할 수 있다. 이 분류 알고리즘은 높은 "편향"치와 높은 "분산"치를 가진다고 볼 수 있겠다. 개발 데이터셋에 대해서 잘 못하여 높은 "편향"이 나타났으며, 개발 데이터셋에 대해서는 그보다 더 잘 못하는 결과로 높은 "분산" 또한 나타났다. 이 경우에, 분류 알고리즘이 동시에 과적합과 희소적합이 나타났으므로 과적합/희소적합 이라는 용어는 적용되기 어렵다.

마지막으로 다음 경우를 한번 살펴 보자:

- 학습 (데이터셋에 대한) 에러율 = 0.5%
- 개발 (데이터셋에 대한) 에러율 = 1%

분류 알고리즘은 매우 잘 작동하고 있다. 낮은 "편향"과 "분산"이 이를 보여준다. 이 경우에는 좋은 성능을 얻을 수 있음을 의미하고, 이를 축하해도 좋을 일이다!