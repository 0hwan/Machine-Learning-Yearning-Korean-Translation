## 32 Plotting learning curves

100개 정도로 구성된 아주 작은 크기의 학습 데이터셋이 있다고 가정해 보자. 10개 단위, 그리고 20개 단위, 그리고 30개 단위,... 100개 단위까지 10씩 증가시키면서, 무작위 선택된 데이터를 사용하여 알고리즘을 학습 시킨다고 생각해 보자. 그러면, 학습 곡선을 10개의 데이터 지점에 대하여 그려볼 수 있을 것이다. 작은 사이즈의 학습 데이터셋일 수록, 곡선이 약간은 기대한 것에 
비교해서 높거나 낮게 노이즈가 낀 것처럼 나타날 지도 모른다.

무작위로 선택된 10개의 데이터에 대해서만 학습을 수행할때, 운이 나빠서 특히나 "나쁜" 모호하거나 잘못 레이블링된 데이터로 이루어진 학습 데이터셋이 걸릴지도 모른다. 또는, 운이 좋아서 특히나 "좋은" 학습 데이터셋이 걸릴 수도 있다. 작은 크기의 학습 데이터셋은 개발과 학습 에러에 무작위하게 변동이 발생할 수도 있음을 의미한다.

개발하는 머신러닝 어플리케이션이 심하게 하나의 종류(class)에 치우치는 경우 (고양이가 없는 데이터의 개수가 고양이가 있는 데이터의 개수에 비해 훨씬 큰 경우의 고양이 분류 작업과 같이), 또는 너무나도 많은 종류(class)가 존재하는 경우 (100가지 동물의 종을 분류하는 것과 같이)에 특히나 "대표성이 없거나" 나쁜 학습 데이터셋을 선택하게될 확률 또한 아주 커진다. 예를 들어보자. 80%의 데이터가 부정의 데이터 (y=0) 라면, 그리고 단지 20%만이 긍정의 데이터 (y=1) 라면, 무작위로 선정된 10개의 데이에 부정의 데이터가 포함되어 있을 확률이 크다. 그리고 이는 알고리즘이 뭔가 의미 있는 것을 학습하는것을 매우 어렵게 만든다.

만약 학습 곡선의 노이즈가 진실된 동향(추세)를 알아차리기 힘들게 만든다면, 여기에는 두 가지 해결책이 존재한다:

- 10개로 이루어진 데이터셋을 10 이외의 무작위로 선택된 몇가지 값들로 (예를 들어서 3-10) 대체해 볼 수 있다. 그리고, 이 데이터에 대해서 한가지 모델만을 학습시키는 것 대신에, 각각의 크기의 데이터셋 (3-10)에 대해서 서로다른 모델을 학습시키고, 각 모델들의 결과에 대한 학습 데이터셋과 개발 데이터셋에 대한 에러를 계산해 볼 수 있다. 학습 에러의 평균과 개발 에러의 평균을 계산해서 이를 그래프로 표현해 보자.

- 만약 학습 데이터셋이 한가지 종류(class)로 치우지는 경우라면, 또는 너무나 많은 종류(class)가 존재하는 경우라면, 무작위로 선택된 10개의 데이터가 아니라 "균형잡힌" 데이터들을 선택해 보자. 예를 들어서, 선택된 데이터의 20%가 긍정의 데이터이고, 80%가 부정의 데이터가 되도록 구성해 볼 수 있다. 더 일반적으로 말해보자면, 각 종류에 대한 데이터의 부분크기들이 오리지널 학습 데이터셋의 전체 크기에 가능한한 근접하도록 구성하는 것을 말한다.

이미 학습 곡선을 그려보았고, 곡선들이 너무나 노이즈가 많이 껴서 동향을 파악하기 어려운 것이 아니라면, 이 기법들을 사용하는것에 크게 신경쓰지 말자. 학습 데이터셋이 10,000개 정도로 거대하고, 종류(class)의 분포가 어느 한쪽으로 치우치지 않았다면, 이 기법들이 아마도 필요 없을 것이다.

마지막으로, 학슷 곡선을 그리는 것은 계산 비용적으로 비싼 행위일 수 있다: 예를 들어서, 1,000개, 2,000개, ... 10,000개 까지 10가지 경우에 대해서 10개의 모델을 학습시켜야 할지도 모른다. 작은 크기의 데이터셋에 대해서 모델을 학습시키는 것은 큰 데이터셋에 대하여 모델을 학습시키는 것보다 더 빠르다. 그렇기 때문에, 위와 같이 균등하게 일직선으로 증가하는 크기의 학습 데이터셋 대신에, 1,000 -> 2,000 -> 4,000 -> 6,000 -> 10,000 처럼 증가하는 크기의 데이터셋에 대하여 학습을 진행해야 할 수 있다. 이렇게 하더라도, 학습 곡선을 통해서 어떤 동향(추세)를 꽤나 깔끔하게 파악하는 것이 가능하다. 물론, 이 기법은 만약 모든 추가적인 모델들을 학습시키는 계산 비용이 중요할때에만 관련이 있다.