## 36 When you should train and test on different distributions

개발된 고양이 사진 어플의 사용자들이 10,000장의 이미지를 업로드 하였고, 그 사진들을 수작업으로 고양이가 포함되어 있는지 아닌지의 레이블링을 수행하였다. 거기에 200,000장의 더 큰 이미지 데이터셋을 인터넷으로부터 다운로드 받아 두었다. 학습/개발/테스트 데이터셋들을 각각 어떻게 정의해야 하는가?

10,000 장의 사용자들의 이미지가, 실제로 어플이 잘 동작해야 하는 데이터에 대한 실질적인 확률분포를 근접하여 반영하기 때문에, 이 데이터를 사용해서 개발 데이터셋과 테스트 데이터셋을 구성해야 할지도 모른다. 데이터에 배고픈(많이 필요한) 딥러닝 알고리즘을 학습시켜야 한다면, 인터넷으로 부터 다운로드된 추가적인 200,000장의 이미지를 학습에 포함시켜야 할지도 모른다. 그렇기 때문에, 학습/개발/테스트 데이터셋이 서로다른 확률분포를 가질 수 있게 된다. 이러한 사실이 어떻게 영향을 미치게 되는가?

데이터를 학습/개발/테스트 데이터셋으로 구분짓는것 대신에, 전체 210,000장의 이미지를 무작위로 섞어서 학습/개발/테스트 데이터셋에 배정할 수 있다. 이 경우에, 모든 데이터가 동일한 분포에서 오게 된다. 그러나, 구성된 개발/테스트 데이터셋의 205,000/210,000 ≈ 97.6% 만큼이 실제 잘 동작해야만 하는 데이터셋을 잘 반영하지 못하는 인터넷에서 수집된 이미지가 될 수 있기 때문에, 개인적으로 이 방법을 추천하고 싶지는 않다. 다음이 개발/테스트 데이터셋을 선택하기 위한 권고 사항임을 기억하자:

- 개발, 테스트 데이터셋이 현재와 미래에 개발하는 시스템이 잘 동작해야만 하는 데이터를 반영하도록 선택하자.

머신러닝에 대한 대부분의 학문들은 학습/개발/테스트 데이터셋 모두가 동일한 분포로부터 구성되는 것을 가정한다. 초기의 머신러닝에서는, 데이터가 부족하곤 했었다. 그래서 보통 몇몇 확률 분포로 그려진 하나의 데이터셋만을 다루었고, 그 데이터를 학습/개발/테스트 데이터셋으로 무작위로 나누었다. 그리곤, 모든 데이터가 동일한 출처로부터 구성되어야 하는 요구사항을 만족한다고 가정하곤 했다.

> 서로 다른 분포를 가지는 학습, 테스트 데이터셋에 관한 몇몇 학문적 연구가 있다. 몇가지 예로, "도메인 적응(domain adaptation)", "트랜스퍼 러닝(transfer learning)", "멀티태스크 러닝(multitask learning)"등이 존재한다. 하지만, 여전히 이론과 현실 사이에틑 커다란 격차가 존재한다. A 라는 데이터셋으로 학습을 진행하고, 완전히 다른 종류의 데이터로 구성된 B로 테스트를 진행하는 경우, 알고리즘이 얼마나 잘 동작하는지에는 "운"이 크게 작용할 수 있을 것이다 ("운" 이라는 것은 연구자들이 특정 작업을 위해서 직접 손으로 디자인한 feature와 아직까지 이해하지 못하는 다른 요소들이 있을 수 있다). 이러한 사실은 학습과 테스트 데이터셋이 서로다른 분포를 가지는 것에 대한 학문적 연구가 시스템적인 차원에서는 성공하기 어렵게 된다.

하지만, 빅데이터라는 시대가 도래하여, 이제는 엄청난 크기의 학습 데이터셋을 인터넷이라는 매체를 통해 접근하는 것이 가능해졌다. 비록 학습 데이터셋이 개발/테스트 데이터셋과는 다른 분포로부터 구성된되는 경우라도, 이 엄청난 데이터를 학습을 위해서 사용하는 것이 가능하다. 데이터가 너무나도 방대해서, 수 많은 정보를 제공할 수 있기 때문이다.

