## 22 Comparing to the optimal error rate

앞서 언급 되어온 고양이를 분류하는 알고리즘 예제에서, ***`최적의`*** 알고리즘이 얻을 수 있는 ***`이상적인`*** 에러율은 거의 0%에 가까울 것이다. 사진을 보는 사람은 사진에 고양이가 있는지, 없는지 항상 알아낼 수 있을 것이다. 그렇기 때문에, 알고리즘을 개발하는 사람은 기계가 그정도로 해낼 수 있기를 바랄 수 있을 것이다.

하지만 다른 종류의 문제라면 더 복잡해질 수 있다. 한가지 예로, 음성인식 시스템을 구축해야 한다고 할 때, 전체 오디오 클립 중 14%가 녹음된 환경이 시끄러운 배경음을 가지고 있으며, 이 때문에 사람 조차도 오디오 클립에 녹음된 음성을 이해할 수 없다고 가정해 보자. 이 경우에 가장 ***`최적의`*** 음성인식 시스템 조차도 14% 수준의 에러율을 가지게 될 수 있다.

이 음성인식의 예에서, 알고리즘의 결과가 다음과 같다고 할때:
- 학습 데이터셋에 대한 에러율 = 15%
- 개발 데이터셋에 대한 에러율 = 30%

학습 데이터셋에 대한 성능은 이미 14%라는 최적의 에러율에 가깝다. 이는 학습 데이터셋에 대한 성능 향상 또는 ***`편향`*** 에 대한 성능 향상에 대한 여지가 별로 없음을 의미한다. 하지만 이 알고리즘은 개발 데이터셋에 대하여 낮은 일반화정도를 보여주고 있다. 그러므로 ***`분산`*** 으로부터의 에러에 대한 성능향상의 여지는 꽤나 존재한다고 볼 수 있다.

이 예제는 앞 챕터의 (마찬가지로 학습 에러율=15%, 개발 에러율=30% 였던) 세번째 예제 와 비슷하다. 만약 최적의 에러율이 거의 ~0% 라면, 학습 데이터셋에 대한 에러율의 개선이 큰 성능 향상에 대한 여지가 있음을 보여준다고 볼 수 있다. 이 상황은 ***`편향`*** 을 줄이는것이 꽤나 생산적임을 말해준다. 하지만 최적의 에러율이 14% 라면, 동일한 학습 데이터셋에 대한 성능은 분류 알고리즘의 ***`편향`*** 에 대한 성능 향상을 위해서 아주 작은 여지만이 있음을 알 수 있게 해준다.

최적의 에러율이 0이 되는것이 어려운 문제에서는 알고리즘에 대한 에러를 좀더 세분화 하여 바라볼 수 있다. 음성인식 예제에 대해서 계속해서 언급해 보자. 30%라는 전체 개발 데이터셋에 대한 에러율은 다음과 같이 세분화 될 수 있다 (비슷한 분석이 테스트와 개발 데이터셋에 대한 에러에도 적용될 수 있다):

- 최적의 에러율 ( ***`피할 수 없는 편향`*** ): 14%. 세상 천지를 통틀어 얻을 수 있는 최고의 음성인식 시스템 조차도 14% 정도의 에러율로 부터 고통 받고 있다고 가정해 보자. 이를 학습 알고리즘의 ***`편향`*** 중에서 ***`피할 수 없는`*** 부분이라고 생각해 볼 수 있다.

- 피할 수 있는 편향: 1%. 학습 데이터셋에 대한 에러율과, 최적의 에러율의 차이로부터 계산 되었다.

> 만약 이 수치가 음수라면, 학습 데이터셋에 대한 성능이 최적의 에러율 보다 더 좋다는 것이다. 즉, 학습 데이터셋에 대해서는 과적합 되었고, 알고리즘이 학습 데이터셋을 너무 과하게 기억하고 있음을 의미한다. ***`편향`*** 을 더 줄이는 방법 보다는 ***`분산`*** 을 줄이는 방법에 초점을 맞추어야 한다.

- 분산: 15%. 개발 데이터셋에 대한 에러율과, 학습 데이터셋에 대한 에러율의 차이로 부터 계산 되었다.

앞의 정의들에 연관지어 볼때, ***`편향`*** 과 ***`피할 수 없는 편향`*** 은 다음과 연관이 있다.

- 편향 = 최적의 에러율( ***`피할 수 없는 편향`*** ) + 피할 수 있는 편향

> 여기서 정의된 것들은 알고리즘을 어떻게 향상시킬지에 대한 통찰력을 얻기 위해서 선택된 것이다. 이 정의들은 통계학자들이 정의하는 ***`편향`*** 과 ***`분산`*** 과는 사뭇 다르다. 기술적으로 말해서, 여기서 내가 ***`편향`*** 이라고 정의한 것은 ***`편향 때문에 발생하는 에러`*** 라고 불려야 하고, ***`피할 수 없는 편향`*** 은 ***`최적의 에러율보다 높은 학습 알고리즘의 편향 때문에 발생하는 에러`*** 라고 불려야 할 것이다.

***`피할수 있는 편향`*** 은 알고리즘이 얼마나 ***`최적의 분류 알고리즘`*** 에 비해서, 학습 데이터셋에 대하여 잘못 동작하는지를 나타낸다.

***`분산`*** 의 컨셉은 이전과 동일하게 유지된다. 엄청나게 많은 학습 데이터를 학습시킴으로써, ***`분산`*** 을 거의 0에 가깝도록 줄이는 것이 이론적으로 가능하다. 그렇기 때문에 충분히 큰 데이터만 있다면, 모든 분산은 ***`피할 수 있는`*** 문제이고 ***`피할 수 없는 분산`*** 과 같은 문제는 존재하지 않는다.

최적의 에러율이 14%인 한가지의 다른 예를 생각해 보자. 이때 알고리즘이 다음과 같은 성능을 보여준다면:
- 학습 데이터셋에 대한 에러율 = 15%
- 개발 데이터셋에 대한 에러율 = 16%

앞 챕터에서는 이와 비슷한 상황에 대하여, 분류 알고리즘이 높은 ***`편향`*** 을 가진다고 이야기한 것과는 다르게 바라볼 수 있다. 여기에는 ***`피할 수 있는 편향`*** 이 1% 존재하며, 분산에 대한 에러율이 1%라고 볼 수 있다. 따라서, 알고리즘의 성능 향상이 이루어지기 위해 아주 작은 여지만이 존재하지만, 꽤나 잘 작동하고 있다고 볼 수 있는 것이다. 최적의 에러율에 비해서 단지 2%의 낮은 성능을 보여준다.

이 예제로부터, 최적의 에러율이란 것이 다음 진행 방향을 개척하는데 도움을 준다는 것을 알 수 있다. 통계학에서 최적의 에러율은 ***`베이즈 에러율`*** 또는 ***`베이즈 에러`*** 라고도 불린다.

그렇다면, 최적의 에러율은 어떻게 알 수 있을까? 사진을 분별하거나 오디오 클립을 기록하는등과 같은 작업에서, 사람들이 최적의 결과를 합리적으로 잘 얻을 수 있기 때문에 사람들에게 레이블링 할 것을 요청할 수 있다. 그리고 이것을 학습 데이터셋과 연관지어 사람이 한 레이블링에 대한 정확도를 측정할 수 있다. 이 과정이 최적의 에러율을 측적할 수 있게 해 줄 것이다. 만약 사람조차 해결하기 어려운 문제(어떤 영화를 추천할까? 사용자에게 어떤 광고를 보여줄까? 같은)에 대해서 고심하고 있다면, 최적의 에러율을 측정하는 것은 어려운 일이다.

***`사람-수준의 성능과 비교하는 것`*** 을 다루는 (챕터 33 에서 35까지) 부분에서는, 학습 알고리즘의 성능을 사람-수준의 성능과 비교하는 과정을 좀 더 상세하게 다룰 것이다.

이때까지 앞의 몇 챕터를 통하여, 학습 데이터셋과 개발 데이터셋에 대한 에러율을 가지고, 어떻게 ***`피할 수 있는`*** / ***`피할 수 없는`*** ***`편향`*** 과 ***`분산`*** 을 측정 가능한지를 배웠다. 다음 챕터는 이러한 분석으로 부터 얻은 통찰력을 통해서, ***`분산`*** 을 줄이는 기법의 사용 vs ***`편향`*** 을 줄이는 기법의 사용에 대한 우선순위를 정하는 방법에 대한 이야기를 할 것이다. 프로젝트가 떠안고 있는 문제가 높은 ***`분산`*** 이냐 높은 ***`피할 수 있는 편향`*** 이냐에 따라서 적용 가능한 기법들이 다양하게 존재한다. 계속 읽어 보자!
